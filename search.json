[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "My research connects mathematical physics to observational astronomy, applying tools from information geometry, gauge theory, and beyond to the challenges of gravitational wave science. By reformulating problems, from source physics to data analysis, through a geometric lens, I develop unified algorithms and derive fundamental results that ensure physical consistency. This approach provides a rigorous framework for solutions extending from instrument calibration to searches for new physics."
  },
  {
    "objectID": "research.html#key-research-areas",
    "href": "research.html#key-research-areas",
    "title": "Research",
    "section": "Key Research Areas",
    "text": "Key Research Areas\n\nGeometric Methods in Gravitational Wave Analysis\n\n\n\nThe core of my work centers on appying geometry to signal processing problems in gravitational wave detection. This includes:\n\nAdaptive Causal Filtering: Standard whitening filters fail when detector noise is non-stationary. By using minimum phase filters, we ensure causality and save latency. We further correct for phase impact in recovery of signals, using geometric methods.\nTemplate Bank Geometry: I also apply information geometry to the problem of “covering” the parameter space of signals. By using the Fisher Information Metric to define the “distance” between waveforms, we can optimize the placement of template banks using high-dimensional sphere-packing algorithms.\n\nKey Work: A Binary Tree Approach to Template Placement (Phys. Rev. D 108).\n\n\n\n\n\n\n\n\n\n\nMultimessenger Astronomy & Early Warning\n\n\n\n\n\n\nGravitational waves are often just the first signal in a cosmic event. To catch the electromagnetic counterpart (light), we need to detect the merger before it happens.\n\nZero/Negative Latency Detection: I work on “Early Warning” pipelines designed to detect binary neutron star inspirals seconds before the collision. This requires pushing signal processing latency to the absolute theoretical minimum (causal limit).\nThe AGN Channel: A major open question is whether binary black holes merge in the vacuum of space or within the accretion disks of Active Galactic Nuclei (AGN). I am investigating methods to use AGN catalogs as “spatial priors” for gravitational wave searches, potentially boosting the significance of sub-threshold events that coincide with known active galaxies.\n\n\n\n\n\n\nExotic Source Searches\n\n\n\nStandard searches assume black holes and neutron stars are the only players in town. I look for what standard pipelines miss.\n\nSub-Solar Mass (SSM) Objects: Searching for compact objects lighter than the Chandrasekhar limit (\\(&lt; 1.4 M_{\\odot}\\)). Since astrophysical mechanisms cannot produce black holes this small, a detection here would be a smoking gun for Primordial Black Holes or non-baryonic dark matter.\n\nKey Work: Template bank for sub-solar mass compact binary mergers.\n\nExotic Compact Objects (ECOs): I am interested in the spectral signatures of physics beyond the Standard Model, including searches for topological solitons (wormholes) and warp drive spacetimes that could mimic black hole signals but lack an event horizon.\n\n\n\n\n\n\n\n\n\nTests of General Relativity & Quantum Gravity\n\n\n\n\n\n\nMy background in Loop Quantum Gravity (working with the Bojowald Group) informs my approach to testing Einstein’s theory.\n\nBlack Hole Spectroscopy: Testing the “No-Hair Theorem” by analyzing the ringdown modes of merging black holes.\nGeometric Constraints: Using the precise phase evolution of gravitational waves to place tight bounds on deviations from General Relativity, effectively using LIGO as a laboratory for quantum gravity phenomenology."
  },
  {
    "objectID": "research.html#selected-publications",
    "href": "research.html#selected-publications",
    "title": "Research",
    "section": "Selected Publications",
    "text": "Selected Publications\n\nGravitational Wave Astronomy\n\nC. Hanna, J. Kennington, et al. A Binary Tree Approach to Template Placement for Searches for Gravitational Waves from Compact Binary Mergers. Physical Review D 108, 042003 (2023).\nC. Hanna, J. Kennington, et al. Template bank for sub-solar mass compact binary mergers in the fourth observing run of Advanced LIGO, Advanced Virgo, and KAGRA. [cite_start]arXiv:2412.10951.\n\n\n\nMathematical Physics & Pedagogy\n\nN. Jeevanjee, J. Kennington. Solutions Manual for An Introduction to Tensors and Group Theory for Physicists. (2019)."
  },
  {
    "objectID": "research.html#selected-talks",
    "href": "research.html#selected-talks",
    "title": "Research",
    "section": "Selected Talks",
    "text": "Selected Talks\n\nMathematical Aspects of Physics (MAP) Seminar (Cofounder & Organizer)\n\nFiber Bundles, Sections, and the Soldering Form (Nov 2024)\nLie Groups and Lie Algebras as Left-Invariant Vector Fields (Oct 2024)\nGravitational Wave Detection as a Covering Problem (Sep 2022)\n\nPrimordial Universe and Gravity Seminar\n\nElements of Information Geometry (Aug 2023)\n\nSIAM Annual Conference (Texas-Louisiana Section)\n\nTensorial methods in optimization (Nov 2019)"
  },
  {
    "objectID": "research.html#full-publication-list",
    "href": "research.html#full-publication-list",
    "title": "Research",
    "section": "Full Publication List",
    "text": "Full Publication List\n\n\n[1] A. G. Abac et al., GW250114: Testing Hawking’s Area Law and the Kerr Nature of Black Holes, Physical Review Letters 135, 111403 (2025).\n\n\n[2] Y.-J. Huang et al., Scalable matched-filtering pipeline for gravitational-wave searches of compact binary mergers, Physical Review D 112, 082002 (2025).\n\n\n[3] A. G. Abac et al., Search for Continuous Gravitational Waves from Known Pulsars in the First Part of the Fourth LIGO-Virgo-KAGRA Observing Run, The Astrophysical Journal 983, 99 (2025).\n\n\n[4] A. G. Abac et al., Search for Gravitational Waves Emitted from SN 2023ixf, The Astrophysical Journal 985, 183 (2025).\n\n\n[5] G. Raman et al., Swift-BAT GUANO Follow-up of Gravitational-wave Triggers in the Third LIGO–Virgo–KAGRA Observing Run, The Astrophysical Journal 980, 207 (2025).\n\n\n[6] C. Hanna et al., Template bank for subsolar mass compact binary mergers in the fourth observing run of Advanced LIGO, Advanced Virgo, and KAGRA, Physical Review D 112, 044013 (2025).\n\n\n[7] A. G. Abac et al., A Search Using GEO600 for Gravitational Waves Coincident with Fast Radio Bursts from SGR 1935+2154, The Astrophysical Journal 977, 255 (2024).\n\n\n[8] A. G. Abac et al., Observation of Gravitational Waves from the Coalescence of a 2.5–4.5 M\\(\\odot\\) Compact Object and a Neutron Star, The Astrophysical Journal Letters 970, L34 (2024).\n\n\n[9] B. Ewing et al., Performance of the low-latency GstLAL inspiral search towards LIGO, Virgo, and KAGRA’s fourth observing run, Physical Review D 109, 042008 (2024).\n\n\n[10] A. G. Abac et al., Search for Eccentric Black Hole Coalescences during the Third Observing Run of LIGO and Virgo, The Astrophysical Journal 973, 132 (2024).\n\n\n[11] S. Schmidt et al., Searching for Asymmetric and Heavily Precessing Binary Black Holes in the Gravitational Wave Data from the LIGO Third Observing Run, Physical Review Letters 133, 201401 (2024).\n\n\n[12] S. Schmidt et al., Searching for gravitational-wave signals from precessing black hole binaries with the GstLAL pipeline, Physical Review D 110, 023038 (2024).\n\n\n[13] S. Sakon et al., Template bank for compact binary mergers in the fourth observing run of Advanced LIGO, Advanced Virgo, and KAGRA, Physical Review D 109, 044066 (2024).\n\n\n[14] A. G. Abac et al., Ultralight vector dark matter search using data from the KAGRA O3GK run, Physical Review D 110, 042001 (2024).\n\n\n[15] C. Hanna et al., Binary tree approach to template placement for searches for gravitational waves from compact binary mergers, Physical Review D 108, 042003 (2023).\n\n\n[16] L. Tsukada et al., Improved ranking statistics of the GstLAL inspiral search for compact binary coalescences, Physical Review D 108, 043004 (2023)."
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Tools & Software",
    "section": "",
    "text": "My research relies on building robust, mathematically rigorous tools. Below is a selection of open-source software I have developed or contributed to, ranging from high-performance signal processing infrastructure to formal proof assistants for mathematical physics."
  },
  {
    "objectID": "tools.html#real-time-infrastructure",
    "href": "tools.html#real-time-infrastructure",
    "title": "Tools & Software",
    "section": "Real-Time Infrastructure",
    "text": "Real-Time Infrastructure\n\nThe sgn Ecosystem\nCore Developer\nI contribute to the sgn framework, a next-generation ecosystem designed for the low-latency requirements of gravitational wave astronomy. My contributions focus on fundamental execution logic as well as detection-specific signal processing details.\n\nsgn: Core library for real-time data processing, providing a modular architecture for building low-latency pipelines.\nsgn-ts: A set of time-series extensions to the core sgn library, enabling efficient handling of streaming data and real-time data processing tasks.\nsgn-ligo: A collection of LIGO-specific extensions to the sgn framework, including optimized implementations of matched filtering and other signal processing techniques tailored for gravitational wave detection.\nsgnl: Detection pipeline and related utilities built on top of the sgn ecosystem, designed to facilitate the development and deployment of real-time detection algorithms. Inheriting conceptually from the GstLAL pipeline.\n\n\n\narray-api-signal\nSole Developer – [Source]\nA lightweight set of signal processing extensions built on the Array API standard. By leveraging the backend detection of array-api-compat, this library provides a unified interface for signal processing primitives (like window functions and filtering) that runs seamlessly on NumPy, PyTorch, or JAX. This library exists to extend the Array API to cover the specific needs of signal processing in gravitational wave astronomy, some of which are not yet covered by the core standard."
  },
  {
    "objectID": "tools.html#geometry-mathematical-physics",
    "href": "tools.html#geometry-mathematical-physics",
    "title": "Tools & Software",
    "section": "Geometry & Mathematical Physics",
    "text": "Geometry & Mathematical Physics\n\nmanifold\nCore Developer – [Source]\nA differential geometry library for constructing geometric template banks. By utilizing information geometry (specifically Fisher information metrics), manifold optimally places templates in high-dimensional parameter spaces. This ensures maximum physical coverage with minimal computational cost by treating the search space as a curved statistical manifold.\n\n\nLoopGroup (Lean 4)\nSole Developer – [Source]\nA formalization of Loop Groups (infinite-dimensional Lie groups) in the Lean 4 theorem prover. Currently under development, this project provides rigorous, computer-verified proofs for the algebraic structures underpinning gauge theory and integrable systems.\n\n\nformality\nSole Developer – [Source]\nA symbolic mathematics extension for sympy focused on combinatorics and finite group theory. Designed as a playground for algebraic experimentation, it provides specialized tools for manipulating Young Tableaux, generating Young Symmetrizer groups, and algorithmically searching for group isomorphisms to verify conjectures."
  },
  {
    "objectID": "tools.html#specialized-utilities",
    "href": "tools.html#specialized-utilities",
    "title": "Tools & Software",
    "section": "Specialized Utilities",
    "text": "Specialized Utilities\n\nzlw (Zero-Latency Whitening)\nSole Developer – [Source]\nA specialized utility library for causal data whitening. Crucial for “Early Warning” detection systems, zlw characterizes noise power spectral densities in real-time without introducing non-causal artifacts (future data leakage), ensuring that analysis pipelines strictly respect the arrow of time.\n\n\nsxolar\nSole Developer – [Source]\nA lightweight, automated interface for the arXiv API. Designed to streamline literature reviews, it automates the tracking and filtering of new preprints in specific sub-fields of mathematical physics and geometry."
  },
  {
    "objectID": "tools.html#pedagogical-resources",
    "href": "tools.html#pedagogical-resources",
    "title": "Tools & Software",
    "section": "Pedagogical Resources",
    "text": "Pedagogical Resources\n\nInteractive Signal Processing\nSole Developer\nA suite of web-based interactive applications designed to visualize the core concepts of matched filtering and gravitational wave detection. These tools allow students and researchers to manipulate signal-to-noise ratios, visualize PSDs, and see real-time template matching in the browser.\n\nDSP Filter Design Playground: See Related Note. An interactive tool for designing and visualizing digital filters, demonstrating the effects of different filter parameters on signal processing tasks, including poles and zeros, frequency response, stability, and causal vs non-causal filtering. Built with Dash and Plotly for an intuitive user experience. Source"
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html",
    "href": "posts/20241101-app-dsp-filter.html",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "",
    "text": "Launch Live App    View Source"
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html#motivation-from-equations-to-intuition",
    "href": "posts/20241101-app-dsp-filter.html#motivation-from-equations-to-intuition",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "Motivation: From Equations to Intuition",
    "text": "Motivation: From Equations to Intuition\nSignal processing is often taught through static diagrams and theorems. We learn that “poles on the left half-plane are stable” or “zeros on the unit circle kill frequencies,” but these concepts remain abstract algebraic rules for many students.\nTo bridge this gap, I built the DSP Filter Design Explorer—an open-source, interactive pedagogical tool built with Python and Dash. It allows students and engineers to “play” with filter topology and see the immediate consequences in both the frequency and time domains.\n\n\n\n\n\n\nFigure 1: The DSP Explorer Interface. Users can drag poles (red) and zeros (blue) to instantly see the effect on the frequency response and impulse response."
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html#key-features",
    "href": "posts/20241101-app-dsp-filter.html#key-features",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "Key Features",
    "text": "Key Features\n\n1. Unified Analog & Digital Design\nThe app unifies the two worlds of DSP by treating them as selectable domains with their own stability logic: * Analog (\\(s\\)-plane): Stability is defined by the Left Half Plane. The imaginary axis (\\(j\\omega\\)) represents frequency. * Digital (\\(z\\)-plane): Stability is defined by the Unit Circle. The angle around the circle represents frequency (from DC to Nyquist).\n\n\n2. Interactive Geometry\nStandard textbook filters (Butterworth, Chebyshev) act as starting points, but you aren’t limited to them. You can grab any pole or zero and drag it to a new location. This allows for “What if?” exploration: What happens if I break the symmetry of this Butterworth filter? What if I move this pole dangerously close to the stability boundary?\n\n\n3. Stability Visualization\nA “Highlight Region” toggle visually demarcates the Causal (Stable) and Anti-Causal regions. * In Analog mode, you see the classic Left/Right plane split. * In Digital mode, you see the interior/exterior of the Unit Disk."
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html#interactive-learning-labs",
    "href": "posts/20241101-app-dsp-filter.html#interactive-learning-labs",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "Interactive Learning Labs",
    "text": "Interactive Learning Labs\nThe best way to build intuition for signal processing is to experiment. Here are five exercises you can run in the app to explore stability, causality, and symmetry.\n\nExperiment 1: The Time-Stability Connection\nSetup: Select Analog mode. Ensure the Causal region is highlighted (Green on the left). Action: Take a single pole from the stable Left Half Plane (Green) and drag it across the vertical axis into the Right Half Plane (Red). Observation: * In Green Zone: The impulse response decays forward in time (\\(t &gt; 0\\)). * On the Line: The signal oscillates forever (Marginally Stable). * In Red Zone: The signal does not explode. Instead, it flips! It now decays backward in time (\\(t &lt; 0\\)).\n\n\n\n\n\n\nNoteWhy does this happen?\n\n\n\n\n\nThis app prioritizes Stability over Causality. Mathematically, a pole in the Right Half Plane (\\(Re(s) &gt; 0\\)) corresponds to an exponential \\(e^{st}\\) that grows infinitely as \\(t \\to \\infty\\). To keep the energy bounded (stable), the math engine treats this pole as “Anti-Causal”—meaning the signal must decay from the future (\\(t=0\\)) back into the past (\\(t \\to -\\infty\\)).\n\n\n\n\n\nExperiment 2: Zeros as “Notches”\nZeros effectively “kill” frequencies. Setup: Click “Reset”, switch to Analog, and click Add Zero. Action: Drag the blue zero directly onto the imaginary axis (the central vertical line) at a specific height (e.g., \\(y=2\\)). Observation: Look at the Bode Plot (Magnitude). You will see a sharp dip (a notch) descending to \\(-\\infty\\) dB at that exact frequency.\n\n\n\n\n\n\nNoteWhy does this happen?\n\n\n\n\n\nThe transfer function is a ratio: \\(H(s) = \\frac{\\text{Zeros}}{\\text{Poles}}\\). If you place a zero exactly at a specific frequency \\(s = j\\omega\\), the numerator becomes zero, and the gain drops to nothing. This is exactly how engineers design filters to remove 60Hz power line hum!\n\n\n\n\n\nExperiment 3: The “Speed vs. Ringing” Trade-off\nSetup: Select Lowpass and Order 4. Action: Toggle between the Butterworth and Chebyshev I families. Observation: * Butterworth: Poles form a wide semi-circle. The impulse response decays quickly but smoothly. * Chebyshev: Poles are squashed into an ellipse closer to the imaginary axis. The impulse response “rings” (oscillates) for much longer.\n\n\n\n\n\n\nNoteWhy does this happen?\n\n\n\n\n\nAs poles move closer to the stability boundary (the imaginary axis), their “damping ratio” decreases. * Butterworth maximizes distance from the axis for a given cutoff, resulting in minimal ringing. * Chebyshev pushes poles closer to the danger zone to get a steeper frequency cutoff, but pays the price with longer time-domain ringing.\n\n\n\n\n\nExperiment 4: Building a Stable Anti-Causal Filter\nTextbooks often say “Anti-Causal filters are impossible.” That is only true for real-time hardware. In data post-processing, they are very real. Setup: Select Analog mode. Action: Drag ALL poles into the Right Half Plane. Observation: You will see a stable, bounded impulse response that exists entirely in negative time (\\(t &lt; 0\\)).\n\n\n\n\n\n\nImportantWhy is this useful?\n\n\n\n\n\nThis demonstrates that “Unstable” poles are only unstable if you force them to process data from the past. If you reverse your data stream (processing from end to start), these “Unstable” poles become stable! This is the core principle behind “Forward-Backward Filtering” (filtfilt), used to smooth data without shifting it in time.\n\n\n\n\n\nExperiment 5: Perfect Symmetry (Zero-Phase)\nSetup: Click “Reset”. Action: Create a symmetric “mirror” image. For every pole you place on the left (e.g., at \\(-1 + 1j\\)), place a matching pole on the right (\\(+1 + 1j\\)). Do the same for the conjugate pairs (bottom half). Observation: The Impulse Response becomes a perfectly symmetric pulse centered at \\(t=0\\).\n\n\n\n\n\n\nTipWhy does this happen?\n\n\n\n\n\nYou have balanced the Phase Delay. * The Left-Hand poles delay the signal (pushing energy to \\(t &gt; 0\\)). * The Right-Hand poles “advance” the signal (pulling energy to \\(t &lt; 0\\)). When balanced perfectly, the phase shifts cancel out, leaving a “Zero-Phase” filter. This preserves the shape of pulses in your data better than any standard causal filter can."
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html#the-tech-stack",
    "href": "posts/20241101-app-dsp-filter.html#the-tech-stack",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "The Tech Stack",
    "text": "The Tech Stack\nThe application is a pure Python stack, demonstrating that you don’t need complex JavaScript frameworks to build high-performance engineering tools.\n\nDash: Handles the frontend UI and client-side state management (dcc.Store), ensuring the app scales to many concurrent users without shared-state conflicts.\nPlotly: Provides the interactive graphing. The drag-and-drop functionality is powered by Plotly’s shape-editing API.\nSciPy: The calculation engine. It handles the complex polynomial algebra (zpk2tf), frequency response (freqs/freqz), and filtering (lfilter/impulse).\nRender: Hosting provider for the Dockerized application.\n\n\nHandling Edge Cases\nOne interesting challenge was handling “Improper” transfer functions. In the analog domain, if a user adds more zeros than poles, the system acts as a differentiator with infinite bandwidth. The app detects this topological violation and displays a warning instead of crashing the solver."
  },
  {
    "objectID": "posts/20241101-app-dsp-filter.html#try-it-yourself",
    "href": "posts/20241101-app-dsp-filter.html#try-it-yourself",
    "title": "Interactive App: Digital Signal Processing Explorer",
    "section": "Try It Yourself",
    "text": "Try It Yourself\nYou can run the app locally or use the hosted version:\npip install dsp-filter-design\ndsp-fd"
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html",
    "href": "posts/20241216-paper-ssmbank.html",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "",
    "text": "Read Paper (ArXiv)    View Code"
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html#the-physics-why-search-below-1-m_odot",
    "href": "posts/20241216-paper-ssmbank.html#the-physics-why-search-below-1-m_odot",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "The Physics: Why Search Below \\(1 M_\\odot\\)?",
    "text": "The Physics: Why Search Below \\(1 M_\\odot\\)?\nStandard stellar evolution tells us that black holes shouldn’t exist below roughly \\(3 M_\\odot\\), and neutron stars likely have a minimum mass around \\(1 M_\\odot\\). So, if we detect a compact object with mass \\(m &lt; 1 M_\\odot\\), it cannot be of stellar origin.\nIt would likely be a Primordial Black Hole (PBH), an object formed from the direct collapse of high-density fluctuations in the early universe, long before the first stars were born. Detecting a sub-solar mass (SSM) merger would not only be the first detection of a PBH but could also provide evidence that PBHs constitute a fraction of Dark Matter.\nIn the fourth observing run (O4) of LIGO-Virgo-KAGRA, we are searching for these elusive signals. But to find them, we needed a new template bank."
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html#the-challenge-geometric-breakdown",
    "href": "posts/20241216-paper-ssmbank.html#the-challenge-geometric-breakdown",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "The Challenge: Geometric Breakdown",
    "text": "The Challenge: Geometric Breakdown\nWe used our geometric Treebank algorithm (described in my previous post) to generate this bank. However, pushing into the sub-solar mass regime (\\(0.2 M_\\odot - 1.0 M_\\odot\\)) broke the standard algorithm.\nThe signal manifold curvature scales with the number of wave cycles. For low-mass binaries, the signals are incredibly long (minutes long), making the metric \\(g_{ij}\\) vary rapidly. We encountered two major singularities: 1. Metric Instability: Numerical derivatives became unstable, leading to non-positive-definite metrics (negative eigenvalues). 2. Boundary Depletion: The “hard cut” at the boundary of the parameter space left the edges under-covered, leading to efficiency loss for the lowest mass signals."
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html#the-solution-neighborhood-estimation",
    "href": "posts/20241216-paper-ssmbank.html#the-solution-neighborhood-estimation",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "The Solution: Neighborhood Estimation",
    "text": "The Solution: Neighborhood Estimation\nTo solve the instability, we generalized the notion of the metric. Instead of calculating \\(g_{ij}\\) at a single point \\(p\\), we implemented Neighborhood Metric Estimation.\nIf the metric calculation fails at \\(p\\), we define a local “trust region” (a hyper-ellipsoid \\(\\mathcal{U}_p\\)) and randomly sample points \\(q_i \\in \\mathcal{U}_p\\) until we find a stable metric. We then transport this metric back to \\(p\\). This allows the algorithm to “step over” numerical singularities while preserving the geometric structure.\n\n\n\n\n\n\nFigure 1: Schematic of the neighborhood metric estimation. If the metric at \\(p\\) is unstable, we sample the local neighborhood (bounded by a mismatch ellipse) to find a stable proxy \\(q_m\\).\n\n\n\nWe also implemented Boundary Padding, effectively generating a secondary “marginal” bank that specifically targets the edges of the parameter space, ensuring that signals right on the \\(0.2 M_\\odot\\) line are recovered with full sensitivity.\n\n\n\n\n\n\nFigure 2: Impact of boundary padding. Left: Original bank shows efficiency loss (lower fitting factor) at low masses. Right: The padded bank recovers nearly all signals with &gt;97% match."
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html#the-result-o4-ssm-bank",
    "href": "posts/20241216-paper-ssmbank.html#the-result-o4-ssm-bank",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "The Result: O4 SSM Bank",
    "text": "The Result: O4 SSM Bank\nThe final product is the O4 Sub-Solar Mass Template Bank detailed in our recent paper.  [1]. It contains 3,452,006 templates covering component masses from \\(0.2 M_\\odot\\) to \\(10 M_\\odot\\).\nThis represents the first successful application of geometric manifold methods to this difficult corner of parameter space. It is currently being used in the GstLAL search pipeline to analyze O4 data. If there are Primordial Black Holes hiding in the noise, this is the net we built to catch them.\n\n\n\n\n\n\nFigure 3: The final O4 SSM Template Bank covering the component mass space. Note the extreme density required at low masses (\\(m &lt; 0.5 M_\\odot\\))."
  },
  {
    "objectID": "posts/20241216-paper-ssmbank.html#references",
    "href": "posts/20241216-paper-ssmbank.html#references",
    "title": "New Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank",
    "section": "References",
    "text": "References\n\n\n[1] C. Hanna et al., Template bank for sub solar mass compact binary mergers in the fourth observing run of Advanced LIGO, Advanced Virgo, and KAGRA, arXiv:2412.10951 (2025)."
  },
  {
    "objectID": "posts/20250120-sxolar.html",
    "href": "posts/20250120-sxolar.html",
    "title": "Keeping Up with ArXiv using Sxolar",
    "section": "",
    "text": "Like many researchers, I use ArXiv to keep up with the latest research in my field. However, I find it difficult to keep track of all the new papers that are posted each day. I have explored many of the existing tools for tracking ArXiv, but I have not found one that meets my simple requirements. All I wanted was a tool that would let me configure a set of queries, and send me periodic emails with the new papers that match those queries. Having found no such tool, I decided to build my own. This post introduces sxolar, a Python library that allows you to search ArXiv, and shows how to use it to keep up with the latest research in your field of interest.\n\n“All I wanted was a tool that would let me configure a set of queries, and send me periodic emails with the new papers that match those queries.”\n\nBefore getting into the simple but robust features of sxolar, let’s take a look at existing tools for tracking ArXiv.\n\n\nThere are several existing tools for tracking ArXiv, but they all have their limitations. Some of the most popular tools include:\n\nArXiv Email Alerts: ArXiv provides an email alert service that allows you to subscribe to new papers in specific categories. However, there is no control over the other elements of the search API, including authors, keywords, etc.\nArXiv Sanity Preserver: A web-based tool that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. However, it does not allow you to configure custom queries. Instead, it uses a machine learning model to recommend papers based on your reading history.\niArXiv: Similar to ArXiv Sanity Preserver, iArXiv is a web-based tool that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. However, it does not allow you to configure custom queries. Instead, it uses a machine learning model to recommend papers based on your reading history.\nArXiv RSS Feeds: ArXiv provides RSS feeds for each category, which you can subscribe to in your favorite RSS reader. However, this requires you to manually check the feeds each day.\nArXiv API: ArXiv provides an API that allows you to search for papers and get metadata about them. However, this requires you to write code to interact with the API.\n\n\n\n\nSxolar is a Python library that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. It is designed to be simple and easy to use, with a focus on customizability and flexibility. It offers a command-line interface, and is easy to use with GitHub actions for automated daily email alerts. Similar to existing wrappers, sxolar uses the ArXiv API to search for papers, and offers the ability to search by authors, keywords, categories, and more. What makes sxolar unique? sxolar can:\n\nSearch by all fields (title, abstract, authors, etc.) as well as arbitrarily complex logical expressions of these fields (e.g., \"title:quantum AND abstract:gravity\").\nSyntactic sugar for building complex queries (e.g., (Title(\"quantum\") & Abstract(\"gravity\")).search()).\nPersist queries to simple configuration files for easy reuse and modification.\nSend email alerts with summaries of new papers that match your queries.\n\nThis library is relatively new, and I am actively developing it. If you have any feature requests or bug reports, please feel free to open an issue on the GitHub repository. I hope you find this tool useful; it has certainly made my life easier!"
  },
  {
    "objectID": "posts/20250120-sxolar.html#overview-motivation",
    "href": "posts/20250120-sxolar.html#overview-motivation",
    "title": "Keeping Up with ArXiv using Sxolar",
    "section": "",
    "text": "Like many researchers, I use ArXiv to keep up with the latest research in my field. However, I find it difficult to keep track of all the new papers that are posted each day. I have explored many of the existing tools for tracking ArXiv, but I have not found one that meets my simple requirements. All I wanted was a tool that would let me configure a set of queries, and send me periodic emails with the new papers that match those queries. Having found no such tool, I decided to build my own. This post introduces sxolar, a Python library that allows you to search ArXiv, and shows how to use it to keep up with the latest research in your field of interest.\n\n“All I wanted was a tool that would let me configure a set of queries, and send me periodic emails with the new papers that match those queries.”\n\nBefore getting into the simple but robust features of sxolar, let’s take a look at existing tools for tracking ArXiv.\n\n\nThere are several existing tools for tracking ArXiv, but they all have their limitations. Some of the most popular tools include:\n\nArXiv Email Alerts: ArXiv provides an email alert service that allows you to subscribe to new papers in specific categories. However, there is no control over the other elements of the search API, including authors, keywords, etc.\nArXiv Sanity Preserver: A web-based tool that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. However, it does not allow you to configure custom queries. Instead, it uses a machine learning model to recommend papers based on your reading history.\niArXiv: Similar to ArXiv Sanity Preserver, iArXiv is a web-based tool that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. However, it does not allow you to configure custom queries. Instead, it uses a machine learning model to recommend papers based on your reading history.\nArXiv RSS Feeds: ArXiv provides RSS feeds for each category, which you can subscribe to in your favorite RSS reader. However, this requires you to manually check the feeds each day.\nArXiv API: ArXiv provides an API that allows you to search for papers and get metadata about them. However, this requires you to write code to interact with the API.\n\n\n\n\nSxolar is a Python library that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. It is designed to be simple and easy to use, with a focus on customizability and flexibility. It offers a command-line interface, and is easy to use with GitHub actions for automated daily email alerts. Similar to existing wrappers, sxolar uses the ArXiv API to search for papers, and offers the ability to search by authors, keywords, categories, and more. What makes sxolar unique? sxolar can:\n\nSearch by all fields (title, abstract, authors, etc.) as well as arbitrarily complex logical expressions of these fields (e.g., \"title:quantum AND abstract:gravity\").\nSyntactic sugar for building complex queries (e.g., (Title(\"quantum\") & Abstract(\"gravity\")).search()).\nPersist queries to simple configuration files for easy reuse and modification.\nSend email alerts with summaries of new papers that match your queries.\n\nThis library is relatively new, and I am actively developing it. If you have any feature requests or bug reports, please feel free to open an issue on the GitHub repository. I hope you find this tool useful; it has certainly made my life easier!"
  },
  {
    "objectID": "posts/20250120-sxolar.html#setting-up-periodic-email-alerts-with-sxolar",
    "href": "posts/20250120-sxolar.html#setting-up-periodic-email-alerts-with-sxolar",
    "title": "Keeping Up with ArXiv using Sxolar",
    "section": "Setting Up Periodic Email Alerts with Sxolar",
    "text": "Setting Up Periodic Email Alerts with Sxolar\nThis post is focused on using sxolar to setup a periodic email digest of ArXiv papers in your field of interest. To see more detailed documentation on the library, please visit the official documentation.  [1] For the purpose of this post, we’ll use my field of study (gravitational waves) to determine a sample query: searching for papers released by the LIGO or VIRGO scientific collaborations. The package also has a tutorial for setting up a periodic digest.  [2]\nThe workflow we are building looks like this:\n\n\n\n\n\nflowchart LR\n    A[Config File] --&gt;|Read by| B(Sxolar Script)\n    C[GitHub Actions] --&gt;|Triggers| B\n    B --&gt;|Queries| D[ArXiv API]\n    D --&gt;|Returns Papers| B\n    B --&gt;|Sends Digest| E[Your Email]\n\n\n\n\n\n\nThis post will be divided into the following steps:\n\nConfiguration of the queries and summary\nSetup of Google Mail Access\nScheduling with GitHub Actions\n\nTo get started with sxolar, you will need to install the library. You can do this using pip:\npip install sxolar\n\nStep 1: Configure the Queries and Summary\nA Summary is a collection of Sections, each of which represents a query with related search parameters (such as time period). The summary info can be persisted to a config file (e.g., summary.yaml) as shown below:\nLIGO Virgo Summary:\n  - name: \"LIGO: Recent 2 Weeks\"\n    authors: [ \"LIGO Scientific Collaboration\" ]\n    alls: [ \"gravitational wave\" ]\n    trailing:\n      num: 14\n      unit: \"days\"\n\n  - name: \"Virgo: Recent 2 Months\"\n    authors: [ \"Virgo Collaboration\" ]\n    alls: [ \"gravitational wave\" ]\n    trailing:\n      num: 2\n      unit: \"months\"\nThe configuration file specifies one summary “LIGO Virgo Summary” with two sections: “LIGO: Recent 2 Weeks” and “Virgo: Recent 2 Months”. Each section specifies the authors, search terms, and trailing time period for the search query. The “trailing” field specifies the number of days or months to search back from the current date.\n\nTesting the Configuration\nThe summary can be generated either using python code or the command line interface. The command-line is relatively simple to use for testing a summary:\nsxolar summary --config summary.yaml --name \"LIGO Virgo Summary\" --output print\nFor more detailed testing, the python library can be used directly. The following code snippet demonstrates how to generate a summary from the config file using python:\nfrom sxolar import Config, Summary\n\n# Load the configuration file, this will also parse the summary objects\nconfig = Config(\"summary.yaml\")\n\n# Get the summary object for \"summary name 1\"\ns1 = config.summaries(\"summary name 1\")\nassert isinstance(s1, Summary)\n\n# Generate the summary first by refreshing the query\ns1.refresh()\n\n# Print the summary (plain)\nprint(s1.to_text())\n\n# Print the summary (html, usually for email)\nprint(s1.to_html())\n\n\n\nStep 2: Setup Google Mail Access\nTo send email alerts, sxolar uses the smtplib library to send emails through a Gmail account. This is made possible (and relatively secure) by using an app password. The library documentation includes instructions for setting up an app password. To set up a Gmail account for sending emails, follow these steps:\n\nGo to App Passwords.\nEnter an app name, e.g. “SampleApp”.\nClick “Create”.\nCopy the generated app password.\n\nThe generated app password is a 16-character code that you will use to authenticate your application.\nApp password: \"abcd efgh ijkl mnop\"\nSpecifically, we will set an environment variable in the GitHub repository to store the app password. This will allow the GitHub Actions to send emails on your behalf.\n\n\nStep 3: Scheduling with GitHub Actions\nTo schedule the email alerts, we will use GitHub Actions. The below snippet is a sample workflow file ( .github/workflows/sxolar.yml) that will run the sxolar summary command weekly on Sunday at 8am EST (1pm UTC). For a sample repository, see sxolar-template-run.\nname: Example Sxolar Run\non:\n  # Uncomment the below to also run on pushes, as a way to test\n  #  push:\n  #      branches:\n  #      - main\n  schedule:\n    # Run Weekly on Sunday at 8am EST (1pm UTC)\n    # For more detail on cron syntax, see https://crontab.guru/\n    - cron: '0 13 * * 0'\n\njobs:\n  MySummary:\n    # Setup the minimal environment: linux and python 3.11\n    name: UNIX Build (${{ matrix.python-version }}, ${{ matrix.os }})\n    runs-on: ${{ matrix.os }}\n    defaults:\n      run:\n        shell: bash -l {0}\n    strategy:\n      fail-fast: false\n      max-parallel: 4\n      matrix:\n        os: [ \"ubuntu-latest\" ]\n        python-version: [ \"3.11\" ]\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      # Install the necessary dependencies (sxolar)\n      - name: Install sxolar\n        run: |\n          pip install sxolar\n\n      # Run the summary using the command line and config file\n      - name: Run GWaves\n        run: |\n          sxolar summary --config configs/gwaves.yml \\\n            --name GWaves \\\n            --email-to myrecipient@gmail.com \\\n            --email-from myemail@gmail.com \\\n            --email-subject \"Sxolar Weekly Digest: GWwaves\" \\\n            --gmail-app-password \"${{ secrets.SXOLARGMAILAPPPASSWORD }}\" \\\n            --output email\nThis workflow file will run the sxolar summary command weekly on Sunday at 8am EST (1pm UTC). The command will use the config file configs/gwaves.yml to generate the summary, and will send the email to myrecipient@gmail.com from myemail@gmail.com. The email will have the subject “Sxolar Weekly Digest: GWwaves”. The app password is stored in the GitHub repository secrets as SXOLARGMAILAPPPASSWORD."
  },
  {
    "objectID": "posts/20250120-sxolar.html#conclusion",
    "href": "posts/20250120-sxolar.html#conclusion",
    "title": "Keeping Up with ArXiv using Sxolar",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we introduced sxolar, a Python library that allows you to search ArXiv and get daily email alerts for new papers in your field of interest. We discussed the limitations of existing tools for tracking ArXiv, and showed how sxolar addresses these limitations. We walked through the process of setting up periodic email alerts with sxolar, including configuring the queries and summary, setting up Google Mail access, and scheduling with GitHub Actions. I hope you find this tool useful for keeping up with the latest research in your field of interest. If you have any feature requests or bug reports, please feel free to open an issue on the GitHub repository. Happy reading!"
  },
  {
    "objectID": "posts/20250120-sxolar.html#references",
    "href": "posts/20250120-sxolar.html#references",
    "title": "Keeping Up with ArXiv using Sxolar",
    "section": "References",
    "text": "References\n\n\n[1] J. W. Kennington, Sxolar: Scholars tools for ArXiv, (2024).\n\n\n[2] J. W. Kennington, Sxolar: Setting up periodic search, (2024)."
  },
  {
    "objectID": "posts/20240518-classifying.html",
    "href": "posts/20240518-classifying.html",
    "title": "Describing Ourselves as Physicists",
    "section": "",
    "text": "Identity in physics can be challenging to find. We’re given a narrow set of labels to choose from, typically theorist or experimentalist, and these can often be time-dependent as we progress in our careers. Throughout my time in the discipline, I’ve worked in experimental labs, theory groups, and more applied settings. Many times I’ve branded myself a theorist, perhaps more out of desire than measure; however, I’ve always wanted a more nuanced way of describing my work, myself, and my developmental stage. Here, I’ve gathered and visualized thoughts on the topic from various sources. Short answer: like most things, it depends on a clever choice of coordinates.\n\n\n\n\n\n\nNoteNote: Speculative\n\n\n\nClassifying people is hard; we’re high-dimensional. The categories illustrated below are best thought of as projections of physicists onto simpler subspaces, the goal of which is to contextualize the distinct character of our work, ourselves, and our development. Caveat lector — I am not an expert in psychology, and no projection can preserve all the detail we possess."
  },
  {
    "objectID": "posts/20240518-classifying.html#overview",
    "href": "posts/20240518-classifying.html#overview",
    "title": "Describing Ourselves as Physicists",
    "section": "",
    "text": "Identity in physics can be challenging to find. We’re given a narrow set of labels to choose from, typically theorist or experimentalist, and these can often be time-dependent as we progress in our careers. Throughout my time in the discipline, I’ve worked in experimental labs, theory groups, and more applied settings. Many times I’ve branded myself a theorist, perhaps more out of desire than measure; however, I’ve always wanted a more nuanced way of describing my work, myself, and my developmental stage. Here, I’ve gathered and visualized thoughts on the topic from various sources. Short answer: like most things, it depends on a clever choice of coordinates.\n\n\n\n\n\n\nNoteNote: Speculative\n\n\n\nClassifying people is hard; we’re high-dimensional. The categories illustrated below are best thought of as projections of physicists onto simpler subspaces, the goal of which is to contextualize the distinct character of our work, ourselves, and our development. Caveat lector — I am not an expert in psychology, and no projection can preserve all the detail we possess."
  },
  {
    "objectID": "posts/20240518-classifying.html#categories-by-approach-to-physics",
    "href": "posts/20240518-classifying.html#categories-by-approach-to-physics",
    "title": "Describing Ourselves as Physicists",
    "section": "Categories by Approach to Physics",
    "text": "Categories by Approach to Physics\nAs physicists we are taught, ab-initio, the distinction between experimental physics and theoretical physics. Where theory seeks answers to fundamental questions about the principles of nature, experiment aims to precisely test existing theories and apply them to practical domains. In doing so, experiment often uncovers new phenomena, which gives theorists a new supply of challenges to tackle.\nWhat this description offers in brevity, it lacks in nuance, especially in an era of increasing sophistication of experiment. The gulf between theory and experiment, created by growing specialization and size of experiment, has allowed more room for phenomenology, or the application of theory to experimental outcomes (often in the form of data). While the distinctions are usually fuzzy in practice, they are often used as absolute descriptors; you can be an experimentalist, or a theorist — that’s it. It’s time that this excluded middle be included as a first-class citizen in the landscape of physics disciplines.\n\n\n\n\n\n\nFigure 1: Types of Physicists\n\n\n\nIn conversation, phenomenology is often muddied with software development. “Isn’t phenomenology just data analysis?” It can be, but it can also be other things. For these reasons, I find it more clear to conceptualize technological sophistication as a separate dimension. Each discipline of experiment, phenomenology, and theory can range from analog methods to advanced programming in practice. The diagram above takes these thoughts into consideration, and includes examples from the LIGO Scientific Collaboration."
  },
  {
    "objectID": "posts/20240518-classifying.html#categories-by-approach-to-thought",
    "href": "posts/20240518-classifying.html#categories-by-approach-to-thought",
    "title": "Describing Ourselves as Physicists",
    "section": "Categories by Approach to Thought",
    "text": "Categories by Approach to Thought\nWhile these categories focus primarily on approaches within theory, I find they apply more broadly to all physicists, since we all encounter theory almost somewhere. This classification is adapted from Martin Bojowald’s popular science book Once Before Time, and uses two dimensions: mathematical v. physical, and analytical v. constructive. The former refers to the preference of tools, formal or intuitive, respectively. The latter refers to the preference of objective, dissecting exiting ideas or conjecturing new ones.\n\n\n\n\n\n\nFigure 2: Types of Theorists\n\n\n\nThe above contains four key examples, which I detail below. Those with knowledge of the development of Loop Quantum Gravity will appreciate the sample theorists included above. To anyone else interested in these historical anecdotes, see  [1].\n\nPhenomenal Physicist. The adrenaline enthusiast guided solely by intuition and concerned only with physical function, a phenomenal physicist wanders through nature in long, powerful strides. By virtue, they are more often wrong than right, and relish the label “crazy.” Consequently, they can usher in radical leaps in models of the universe, but must also be constrained by all the other types of theorist.\nPhilosopher Physicist. Ever focused on deep physical concepts, the philosopher physicist prides themselves on the artistry of intuitive reasoning. Often seen quoting poetry or literature, they seek the foundational meaning of ontology and epistemology in physics, and therefore can tend to be both profoundly insightful and impractical.\nMathematical Analyst. Often misunderstood as nitpicking, the mathematical analyst is a meticulous tool-bearer who can’t readily accept a physical theory until all the mathematical details have been sorted. At their humble best, they can advance and crystallize laws underlying existing physical theory. However, at worst, they may take known results, refurbish, and resell them as new findings.\nMathematical Constructor. A tinkerer of symbolic expressions, the mathematical constructor loves to build and study new classes of formal objects in the hope of advancing theory. Capable of enduring long and tedious progress, they can indulge in tremendously convoluted detail; however, this can often produce mathematically-fruitful detours on which the relation to physics is lost."
  },
  {
    "objectID": "posts/20240518-classifying.html#categories-by-career-development-stage",
    "href": "posts/20240518-classifying.html#categories-by-career-development-stage",
    "title": "Describing Ourselves as Physicists",
    "section": "Categories by Career Development Stage",
    "text": "Categories by Career Development Stage\nAs we are wont to do as physicists, we have first established a kinematic picture, and now want to stir in some dynamics. While the trajectory of my career might look like a particle in a box in the above two categorizations, this next classification seems more one-size-fits-all. Put forth by the eminent Terry Tao, this system describes the usage and reliance upon mathematical rigor throughout the career of a mathematician. I find that it aptly describes the usage of mathematics in physics as well, particularly for theorists.\n\n\n\n\n\n\nFigure 3: Stages of Rigor\n\n\n\nThe classification above has three stages: pre-rigorous, rigorous, and post-rigorous, which we describe below. For the original piece by Tao, see  [2].\n\nStage I: Pre-Rigorous. Wave those hands, and sweep those details under the rug. This stage is all about “shut up and calculate,” with priority being given to ability to complete computations over understanding of the underlying mechanics. Relying heavily on examples (think, harmonic oscillator!), this stage can lean on intuition and coarse, fuzzy concepts. If you’ve found yourself pioneering interpretive dance moves during an exam while using the right-hand rule, you’ve been here. Tao suggests this stage lasts until the early undergraduate years for mathematicians (perhaps slightly longer for physicists).\nStage II: Rigorous. Rewind the tape, it’s time to check the fundamentals. This stage is primarily concerned with doing things the “proper” way, and often involves revisiting previously learned material in considerably increased depth. In mathematics, this can mean a focus on formal and symbolic precision as well as rebuilding known results with deeper understanding of method, not necessarily of meaning. In physics, we also revisit old topics with new mathematical tools; however, we also partially prioritize the meaning of physical principles and how they apply to given settings. Tao suggests this stage lasts from late undergraduate to early graduate years.\nStage III: Post-Rigorous. Settle in and let the tea steep. This stage is focused on the continual refinement of intuition, based on a fully-rigorous understanding of the foundations. For example, quickly performing simplified calculations in GR by using symmetries, then being able to go back and fully expand the detail if required. The focus here is now on field-specific applications of theory, intuitive exploration of research topics, and the “big-picture” contextualizing and shaping how specific research fits within physical frameworks. Tao suggests this stage lasts from late graduate years and beyond.\n\nOne particular point of Tao’s that I appreciate as a physicist doing mathematics, is that rigor is not meant to destroy intuition, but rather to correct, clarify, and elevate it."
  },
  {
    "objectID": "posts/20240518-classifying.html#conclusion-self-classification",
    "href": "posts/20240518-classifying.html#conclusion-self-classification",
    "title": "Describing Ourselves as Physicists",
    "section": "Conclusion: Self-Classification",
    "text": "Conclusion: Self-Classification\nWhile the search for ideal coordinates never ends, the above three systems have at least given me more terms to describe my work, myself, and my career. As of the time of this writing, and if all axes are bounded on \\([0, 1]\\) in the first two systems, I have approximate coordinates (0.8, 0.8) in the first system, (0.2, -0.8) in the second, and (2.9) in the third.\nThanks to Joshua Black, Cort Posnansky, Matthew Krebs, Chad Hanna, Martin Bojowald, and Garrett Wendel for their helpful discussion and consideration of these topics over many conversations."
  },
  {
    "objectID": "posts/20240518-classifying.html#references",
    "href": "posts/20240518-classifying.html#references",
    "title": "Describing Ourselves as Physicists",
    "section": "References",
    "text": "References\n\n\n[1] M. Bojowald, Once Before Time: A Whole Story of the Universe (Vintage Books, New York, NY, 2010).\n\n\n[2] T. Tao, There’s more to mathematics than rigour and proofs, (2009)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jim W. Kennington",
    "section": "",
    "text": "I am a theoretical physicist applying geometry to gravitational wave astronomy, developing frameworks for compact binary coalescence (CBC) detection pipelines that operate in the non-stationary noise of the cosmos. I also contribute to searches for multi-messenger and early-warning events, exotic compact objects, and tests of general relativity / quantum gravity with gravitational waves. I am a member of the LIGO Scientific Collaboration and the LISA Consortium."
  },
  {
    "objectID": "index.html#whats-new",
    "href": "index.html#whats-new",
    "title": "Jim W. Kennington",
    "section": "What’s New",
    "text": "What’s New\n\n\n\n\n\n\n\n\n\n\nKeeping Up with ArXiv using Sxolar\n\n\n\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank\n\n\nA new paper presenting a novel template bank for sub-solar mass black hole searches in LIGO’s O4 run.\n\n\n\nDec 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive App: Digital Signal Processing Explorer\n\n\nAn interactive web app to explore digital signal processing concepts through pole-zero manipulation.\n\n\n\nNov 1, 2024\n\n\n\n\n\n\nNo matching items\n\n\nView all notes →\n\n\n  Email \n  CV \n  Github \n  LIGO \n  Inspire \n  ADS \narXiv \n  ORCID \n  ResearchGate \n  LinkedIn"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Keeping Up with ArXiv using Sxolar\n\n\n\nPhysics\n\nCode\n\n\n\n\n\n\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nNew Paper: Hunting for Primordial Black Holes, The O4 Sub-Solar Mass Bank\n\n\n\nResearch\n\nLIGO\n\nDark Matter\n\nPaper\n\n\n\nA new paper presenting a novel template bank for sub-solar mass black hole searches in LIGO’s O4 run.\n\n\n\n\n\nDec 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive App: Digital Signal Processing Explorer\n\n\n\nCode\n\nPhysics\n\nSignal Processing\n\nEducation\n\n\n\nAn interactive web app to explore digital signal processing concepts through pole-zero manipulation.\n\n\n\n\n\nNov 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDescribing Ourselves as Physicists\n\n\n\nPhysics\n\n\n\n\n\n\n\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNamespacing SSH Credentials with Git\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNew Paper: Geometric Template Placement with Binary Trees\n\n\n\nResearch\n\nCode\n\nGeometry\n\nPaper\n\n\n\nA new paper presenting a novel algorithm for geometric template placement using binary trees.\n\n\n\n\n\nSep 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRecent Finds #1\n\n\n\nPhysics\n\nMath\n\n\n\n\n\n\n\n\n\nSep 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nAlgebra Ladder\n\n\n\nMath\n\nAlgebra\n\nGroup Theory\n\n\n\n\n\n\n\n\n\nMar 15, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review: Tensors and Group Theory for Physicists (Jeevanjee)\n\n\n\nBooks\n\nPhysics\n\nMath\n\n\n\n\n\n\n\n\n\nJun 28, 2019\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html",
    "href": "posts/20240304-ssh-namespacing.html",
    "title": "Namespacing SSH Credentials with Git",
    "section": "",
    "text": "Why would you ever want to namespace your SSH credentials with Git? If you have multiple accounts on the same Git hosting service, you might want to use different SSH keys for each account. This is a common scenario for developers who have both personal and work accounts on GitHub, GitLab, or Bitbucket. This post will show you how to set up SSH namespaces with Git, so you can use different SSH keys for different accounts on various hosting services."
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html#why-namespace-ssh-credentials-with-git",
    "href": "posts/20240304-ssh-namespacing.html#why-namespace-ssh-credentials-with-git",
    "title": "Namespacing SSH Credentials with Git",
    "section": "",
    "text": "Why would you ever want to namespace your SSH credentials with Git? If you have multiple accounts on the same Git hosting service, you might want to use different SSH keys for each account. This is a common scenario for developers who have both personal and work accounts on GitHub, GitLab, or Bitbucket. This post will show you how to set up SSH namespaces with Git, so you can use different SSH keys for different accounts on various hosting services."
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html#overview",
    "href": "posts/20240304-ssh-namespacing.html#overview",
    "title": "Namespacing SSH Credentials with Git",
    "section": "Overview",
    "text": "Overview\nTo successfully namespace SSH credentials with Git required several steps. Before we detail these steps, let’s first look at the high-level overview of the process. We begin by explaining the meaning of a ssh namespace, then outline the general flow of the process, including the call stack layers of both git and ssh. If you want to skip this overview and begin setting up your namespaces, you can jump to the next section.\n\nSSH Namespaces\nAn SSH namespace is essentially a description of which SSH keys to use for which repositories. Specifically, it is a combination of:\n\nA git host (e.g. github.com, gitlab.com, bitbucket.org)\nA namespace within that host (e.g. a username or organization name)\nAn SSH key to use for that namespace\nOne or more repositories within that namespace\nA local directory containing all the relevant repositories\n\n\n\nGeneral Flow of Git and SSH\nThe general flow of the process is outlined in the diagram below. It begins with a call to git, which then uses configuration files to determine a namespace. This namespace is then used to determine how to modify the url for the subsequent call to ssh. The ssh call then uses the url to determine which key to use.\n\n\n\n\n\n\nFigure 1: General Flow Diagram of Git and SSH call stack.\n\n\n\nWhere the numbered steps correspond to the steps in the following section."
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html#setting-up-namespaces-4-steps",
    "href": "posts/20240304-ssh-namespacing.html#setting-up-namespaces-4-steps",
    "title": "Namespacing SSH Credentials with Git",
    "section": "Setting Up Namespaces: 4 Steps",
    "text": "Setting Up Namespaces: 4 Steps\nFor this walkthrough, we will implement 3 namespaces, two for GitHub and one for GitLab. All source code will be stored locally under the ~/code directory, under which we will create subdirectories for each namespace.\n\nStep 0: Prerequisites\nBefore we begin, we need to establish the context for the 3 namespaces. We will use the following as examples of the Host/Account/Email/Repo combinations that might motivate the use of namespaces:\n\nName: personal\n\nHost: GitHub\nAccount: personal\nEmail: personal@email.com\nRepos: repo1 and repo2\n\nName: work\n\nHost: GitHub\nAccount: organization\nEmail: work@email.com\nRepos: repo3 and repo4\n\nName: collab\n\nHost: GitLab\nAccount: collab\nEmail: collab@email.com\nRepos: repo5 and repo6\n\n\n\n\nStep 1: Create SSH Keys and Add to Hosts\nFirst, we need to create SSH keys for each namespace. We will create 3 keys, one for each namespace. We will use the default names for the keys, id_ed25519_{name} and id_ed25519_{name}.pub, and store them in the default location, ~/.ssh. For creating the keys, we can use the following commands:\nssh-keygen -t ed25519 -C \"{email}\" -f ~/.ssh/id_ed25519_{name}\nWhere {email} is the email associated with the namespace. For example, for the personal namespace, we would use:\nssh-keygen -t ed25519 -C \"personal@email.com\" -f ~/.ssh/id_ed25519_personal\nMake sure that these keys are added to the appropriate host. The GitHub and GitLab documentation provide instructions for adding SSH keys to your account.  [1,2]\n\n\nStep 2: SSH Key Routing\nNext, we need to create an SSH config file to route the namespaces to the appropriate keys. We will create a file at ~/.ssh/config with the following contents:\nHost github.com-organization\nHostName github.com\nUseKeychain yes\nAddKeysToAgent yes\nUser git\nIdentityFile ~/.ssh/id_ed25519_work\nIdentitiesOnly yes\n\nHost github.com-personal\nHostName github.com\nUseKeychain yes\nAddKeysToAgent yes\nUser git\nIdentityFile ~/.ssh/id_ed25519_personal\nIdentitiesOnly yes\n\nHost gitlab.com-collab\nHostName gitlab.com\nUseKeychain yes\nAddKeysToAgent yes\nUser git\nIdentityFile ~/.ssh/id_ed25519_collab\nIdentitiesOnly yes\nThis file tells SSH to use the appropriate key for each namespace. The Host lines define the namespace, and the IdentityFile lines define the key to use for that namespace. The IdentitiesOnly line tells SSH to only use the specified key for that namespace. We will use git url modification to route the namespaces to the appropriate host.\n\n\nStep 3: Git Namespace Configs\nNext, we need to tell git how to configure each namespace. This is achieved by creating a .gitconfig file in the root directory of each namespace. Specific examples are provided below for the three namespaces in this walkthrough.\nThe file ~/code/personal/.gitconfig should contain the following:\n[user]\n  email = personal@email.com\n  \n[url \"git@github.com-personal\"]\n  insteadOf = git@github.com\nThe file ~/code/work/.gitconfig should contain the following:\n[user]\n  email = work@email.com\n  \n[url \"git@github.com-organization\"]\n  insteadOf = git@github.com\nThe file ~/code/collab/.gitconfig should contain the following:\n[user]\n  email = collab@email.com\n  \n[url \"git@gitlab.com-collab\"]\n  insteadOf = git@gitlab.com\nThese files tell git to modify the host name for each namespace. The user section specifies the email to use for each namespace, and the url section specifies the namespace and the host to use for that namespace. We need one more step, though, to make this work.\n\n\nStep 4: Git Namespace Routing\nThe final step is to tell git to use the ~/code/{name}/.gitconfig files for each namespace. This is achieved by modifying the overall ~/.gitconfig file to include the following:\n[includeif \"gitdir:~/code/personal/\"]\n    path = ~/code/personal/.gitconfig\n    \n[includeif \"gitdir:~/code/work/\"]\n    path = ~/code/work/.gitconfig\n\n[includeif \"gitdir:~/code/collab/\"]\n    path = ~/code/collab/.gitconfig\nThis tells git to use the appropriate .gitconfig file for each namespace. The includeif lines specify the directory to use for each namespace, and the path lines specify the .gitconfig file to use for that namespace.\n\n\n\n\n\n\nTipNote: Trailing Forward Slash in gitdir\n\n\n\nThe gitdir path should include a trailing forward slash. This is because git uses the gitdir path to match the directory of the repository, and the trailing forward slash behaves like a recursive glob pattern, e.g. ~code/personal/**."
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html#using-namespaces",
    "href": "posts/20240304-ssh-namespacing.html#using-namespaces",
    "title": "Namespacing SSH Credentials with Git",
    "section": "Using Namespaces",
    "text": "Using Namespaces\nOnce the namespaces are set up, you can use them as you would use any other git repository. For example, to clone a repository in the personal namespace, you would use the following command:\n# Change working directory\ncd ~/code/personal\n\n# Clone repository\ngit clone git@github.com:personal/repo1.git\n\n\n\n\n\n\nTipNote: Working Directory\n\n\n\nThe git routing works based on the working directory when the command is run. This means that you need to be in the appropriate directory for the namespace you want to use. For example, to use the personal namespace, you would need to be in the ~/code/personal directory.\n\n\nThat’s it! You should now be able to use different SSH keys for different accounts on the same Git hosting service."
  },
  {
    "objectID": "posts/20240304-ssh-namespacing.html#references",
    "href": "posts/20240304-ssh-namespacing.html#references",
    "title": "Namespacing SSH Credentials with Git",
    "section": "References",
    "text": "References\nThis post was adapted from and inspired by several sources, with a few key changes and summary.  [3–5]\n\n\n[1] Adding a new SSH key to your GitHub account, (n.d.).\n\n\n[2] Use SSH keys to communicate with GitLab, (n.d.).\n\n\n[3] M. Vance, GitHub BitBucket multiple SSH keys, (n.d.).\n\n\n[4] B. Jacob, How to manage multiple GitHub accounts on a single machine with SSH keys, (2021).\n\n\n[5] C. Russell, SSH keys with multiple GitHub accounts, (2019)."
  },
  {
    "objectID": "posts/20200315-algebra-ladder.html",
    "href": "posts/20200315-algebra-ladder.html",
    "title": "Algebra Ladder",
    "section": "",
    "text": "I first encountered a diagram of algebraic structures at the end of Jeevanjee’s second chapter, “Vector Spaces”, which elegantly summarizes the high-level differences in structure between sets, vector spaces, and inner product spaces.  [1]\nThis diagram was immensely helpful to me, in that it helped show the relationships between various commonly used objects in mathematical physics. As I’ve encountered new structures, I’ve attempted to augment this map along two dimensions: a structure dimension that aims to measure the number of attributes an algebraic object has, and a specificity dimension which measures the amount of constraints placed on each attribute.\nFor instance, a Magma has more structure than a set, because a new attribute—a binary operator—has been added. A Group, though, is roughly similar in structure to a magma, but has more properties of the binary operator specified, such as associativity, inverses, and identity, which make it more specific (and the magma more general).  [2]\nThe diagram above aims to show how an algebra is constructed from a set, though admittedly omits several algebraic structures along the way. I’ve attempted to include the most primary objects used or seen in mathematical physics. I should also note, this diagram is intended as a quick-reference, and isn’t a substitute for opening Hungerford!  [3]"
  },
  {
    "objectID": "posts/20200315-algebra-ladder.html#references",
    "href": "posts/20200315-algebra-ladder.html#references",
    "title": "Algebra Ladder",
    "section": "References",
    "text": "References\n\n\n[1] N. Jeevanjee, An Introduction to Tensors and Group Theory for Physicists (Springer Science+Business Media, New York, NY, 2015).\n\n\n[2] S. Roman, Advanced Linear Algebra, 3rd ed (Springer, New York, 2007).\n\n\n[3] T. W. Hungerford, Algebra, Nachdr. (Springer, New York, NY, 2008)."
  },
  {
    "objectID": "posts/20190628-book-review-jeevanjee.html",
    "href": "posts/20190628-book-review-jeevanjee.html",
    "title": "Book Review: Tensors and Group Theory for Physicists (Jeevanjee)",
    "section": "",
    "text": "I picked up a copy of Nadir Jeevnajee’s An Introduction to Tensors and Group Theory for Physicists a few months ago with the intent of skimming through and spending most of my time in reference texts. To my pleasant surprise, I found this text to be self-contained — requiring little to no references. The presentation is at once mathematically rigorous and physically intuitive, alluding to well-known examples from physics throughout. I’ve found this text to be such a great introduction to tensors that I have even recommended it to computer-scientist colleagues of mine who have no interest in physics. I whole-heartedly recommend it to anyone interesting in becoming more familiar with tensors and elementary group / representation theory.  [1]\n\n\nThe presentation of tensors as multilinear functions achieves a remarkable degree of exposition, and arrives at all the more heuristic definitions of tensors as derived from the simple multilinear-map definitions. This gave the impression of a more solid ground basis for many subsequent tensorial notations and usages.\nThe derivation of commonly assumed definitions is most satisfying. Specifically, the definitions of the adjoint operator and tensor product are much simpler than the more commonly given “behavioral” definitions presented in physics. I appreciated the rigorous yet succinct treatment of the tensor and wedge products.\n\n\n\nThough I am still working through the last part of chapter 6, I must admit I found this section to be superbly clear. The methodical, sequential development of topics in Lie theory were especially thoughtful. The presentation of Lie algebra elements as derivatives of Lie group elements yielded the conventional tangent-space definitions nicely.\nAt the same time, Jeevanjee also presents many common groups and the important relations between them, such as the double-cover relationship of \\(SU(2)\\) and \\(SO(3)\\). He also presents the higher-level relations between the various common groups, such as the quantum implications of the Lorentz (improper) group. Good stuff!"
  },
  {
    "objectID": "posts/20190628-book-review-jeevanjee.html#summary",
    "href": "posts/20190628-book-review-jeevanjee.html#summary",
    "title": "Book Review: Tensors and Group Theory for Physicists (Jeevanjee)",
    "section": "",
    "text": "I picked up a copy of Nadir Jeevnajee’s An Introduction to Tensors and Group Theory for Physicists a few months ago with the intent of skimming through and spending most of my time in reference texts. To my pleasant surprise, I found this text to be self-contained — requiring little to no references. The presentation is at once mathematically rigorous and physically intuitive, alluding to well-known examples from physics throughout. I’ve found this text to be such a great introduction to tensors that I have even recommended it to computer-scientist colleagues of mine who have no interest in physics. I whole-heartedly recommend it to anyone interesting in becoming more familiar with tensors and elementary group / representation theory.  [1]\n\n\nThe presentation of tensors as multilinear functions achieves a remarkable degree of exposition, and arrives at all the more heuristic definitions of tensors as derived from the simple multilinear-map definitions. This gave the impression of a more solid ground basis for many subsequent tensorial notations and usages.\nThe derivation of commonly assumed definitions is most satisfying. Specifically, the definitions of the adjoint operator and tensor product are much simpler than the more commonly given “behavioral” definitions presented in physics. I appreciated the rigorous yet succinct treatment of the tensor and wedge products.\n\n\n\nThough I am still working through the last part of chapter 6, I must admit I found this section to be superbly clear. The methodical, sequential development of topics in Lie theory were especially thoughtful. The presentation of Lie algebra elements as derivatives of Lie group elements yielded the conventional tangent-space definitions nicely.\nAt the same time, Jeevanjee also presents many common groups and the important relations between them, such as the double-cover relationship of \\(SU(2)\\) and \\(SO(3)\\). He also presents the higher-level relations between the various common groups, such as the quantum implications of the Lorentz (improper) group. Good stuff!"
  },
  {
    "objectID": "posts/20190628-book-review-jeevanjee.html#solutions",
    "href": "posts/20190628-book-review-jeevanjee.html#solutions",
    "title": "Book Review: Tensors and Group Theory for Physicists (Jeevanjee)",
    "section": "Solutions",
    "text": "Solutions\nAs I read through the text I’m compiling some solutions. Much to my fortunate surprise, Dr. Jeevanjee has welcomed these solutions as contributions to his solutions manual which he has published on Overleaf here: Solutions Manual."
  },
  {
    "objectID": "posts/20190628-book-review-jeevanjee.html#references",
    "href": "posts/20190628-book-review-jeevanjee.html#references",
    "title": "Book Review: Tensors and Group Theory for Physicists (Jeevanjee)",
    "section": "References",
    "text": "References\n\n\n[1] N. Jeevanjee, An Introduction to Tensors and Group Theory for Physicists (Springer Science+Business Media, New York, NY, 2015)."
  },
  {
    "objectID": "posts/20220922-paper-manifold.html",
    "href": "posts/20220922-paper-manifold.html",
    "title": "New Paper: Geometric Template Placement with Binary Trees",
    "section": "",
    "text": "Read Paper (ArXiv)    View Code (PyPi)"
  },
  {
    "objectID": "posts/20220922-paper-manifold.html#matched-filtering-on-curved-manifolds",
    "href": "posts/20220922-paper-manifold.html#matched-filtering-on-curved-manifolds",
    "title": "New Paper: Geometric Template Placement with Binary Trees",
    "section": "Matched Filtering on Curved Manifolds",
    "text": "Matched Filtering on Curved Manifolds\nIn gravitational wave astronomy, the optimal strategy for detecting signals buried in Gaussian noise is matched filtering. This requires a discrete set of waveform filters, or a Template Bank, \\(\\{h(\\vec{\\theta}_i)\\}\\), that covers the continuous parameter space of compact binary mergers. The effectiveness of a bank is measured by the mismatch—the fractional loss in signal-to-noise ratio (SNR) due to the discreteness of the grid.\nConstructing these banks is a problem of differential geometry. The parameter space \\(\\mathcal{M}\\) (masses, spins) is a Riemannian manifold endowed with a metric \\(g_{ij}\\) defined by the inner product of the waveform derivatives. The distance between two points on this manifold represents the loss in SNR:\n\\[\n1 - \\mathcal{M} \\approx g_{ij} \\Delta \\theta^i \\Delta \\theta^j\n\\]\nBecause the metric depends on the coordinates (the manifold is curved), the local density of templates required to maintain a fixed minimal match is proportional to \\(\\sqrt{|g|}\\). In the low-mass regime, the curvature is high, requiring dense placement; at high masses, the manifold flattens out. Historically, the field has relied on stochastic placement—randomly sampling points and rejecting those too close to existing templates. While robust, this is computationally expensive (\\(O(N^2)\\) without heuristics) and produces an unstructured, amorphous set of points."
  },
  {
    "objectID": "posts/20220922-paper-manifold.html#recursive-decomposition",
    "href": "posts/20220922-paper-manifold.html#recursive-decomposition",
    "title": "New Paper: Geometric Template Placement with Binary Trees",
    "section": "Recursive Decomposition",
    "text": "Recursive Decomposition\nIn our paper, A binary tree approach to template placement, we propose a deterministic, geometric alternative: Treebank.  [1]\nWe approach the problem as a recursive binary space partitioning task. We initialize the search space as a single hyper-rectangle and recursively subdivide it based on the local Riemannian geometry. For a given hyper-rectangle, we calculate the metric \\(g_{ij}\\) at the centroid and estimate the number of templates \\(\\mathcal{N}\\) required to cover its proper volume.\nThe algorithm proceeds as follows:\n\nMetric Evaluation: Calculate the proper length of each edge of the hypercube using the local metric.\nBifurcation: If \\(\\mathcal{N} &gt; 1\\), split the hypercube in half along the dimension with the largest proper length.\nRecursion: Repeat the process for the resulting child nodes.\nPlacement: When \\(\\mathcal{N} \\approx 1\\), the recursion terminates, and a template is placed at the geometric center.\n\n\n\n\n\n\n\nFigure 1: Binary tree decomposition of the parameter space. The numbers represent the recursion depth, illustrating how the algorithm adapts to the local curvature of the signal manifold."
  },
  {
    "objectID": "posts/20220922-paper-manifold.html#geometric-structure-and-efficiency",
    "href": "posts/20220922-paper-manifold.html#geometric-structure-and-efficiency",
    "title": "New Paper: Geometric Template Placement with Binary Trees",
    "section": "Geometric Structure and Efficiency",
    "text": "Geometric Structure and Efficiency\nThis approach effectively translates a physics problem—covering a signal manifold—into a classic computer science structure, the \\(k\\)-d tree.\nThe computational gains are significant; we generated a bank suitable for Advanced LIGO (covering component masses \\(1 M_\\odot &lt; m_{1,2} &lt; 100 M_\\odot\\)) in approximately 24 CPU-hours, a task that can take days with stochastic methods.\nHowever, the primary advantage is structural. Stochastic banks are unstructured point clouds. The Treebank algorithm partitions the parameter space into non-overlapping hyper-rectangles, where each template “owns” a specific, well-defined volume of the physical parameter space. This structure simplifies downstream Bayesian inference and population modeling, as numerical integration over the parameter space becomes a summation over defined Euclidean volumes weighted by the local metric.\n\n\n\n\n\n\nFigure 2: The resulting template bank covering the component mass space. Note the varying density of templates, inversely proportional to the chirp mass.\n\n\n\nWe produced a bank of \\(\\sim 2 \\times 10^6\\) templates. While the geometric constraints force a slightly higher number of templates than stochastic limits to achieve the same minimal match, the average match is higher, potentially improving the overall detection efficiency of the search pipeline.\nYou can view the code for this project here: gwsci-manifold"
  },
  {
    "objectID": "posts/20220922-paper-manifold.html#references",
    "href": "posts/20220922-paper-manifold.html#references",
    "title": "New Paper: Geometric Template Placement with Binary Trees",
    "section": "References",
    "text": "References\n\n\n[1] C. Hanna et al., A binary tree approach to template placement for searches for gravitational waves from compact binary mergers, arXiv:2209.11298 (2022)."
  },
  {
    "objectID": "posts/20210919-recent-finds.html",
    "href": "posts/20210919-recent-finds.html",
    "title": "Recent Finds #1",
    "section": "",
    "text": "NoteMotivation\n\n\n\nAs this is the inaugural issue of the recent finds series, I’ll briefly note my motivation and inspiration. The title of this series is an overt nod to the famous series This Week’s Finds written by the inimitable John Baez. I have learned a great deal from that series and his book on gravity, and have the utmost admiration for Baez’s abilities as a physicist and communicator. It is my hope that this series will be found useful by some, insightful by at least a few, and accessible by many."
  },
  {
    "objectID": "posts/20210919-recent-finds.html#algebraic-and-geometric-equivalence-of-tangent-vectors",
    "href": "posts/20210919-recent-finds.html#algebraic-and-geometric-equivalence-of-tangent-vectors",
    "title": "Recent Finds #1",
    "section": "Algebraic and Geometric Equivalence of Tangent Vectors",
    "text": "Algebraic and Geometric Equivalence of Tangent Vectors\nAs will likely come up in future posts, I’m thoroughly enjoying Modern Differential Geometry for Physicists by Chris Isham. He develops formalism and intuition without sacrificing rigor, all while carrying a conversational tone. See my reference review for more.  [1]\nMost students of physics or calculus are generally familiar with the notion of a tangent vector. This concept becomes more nuanced, of course, when the ambient space is generalized from \\(\\mathbb{R}^n\\) to a manifold \\(\\mathcal{M}\\) of dimension \\(n\\). Isham takes an unusual approach to formalizing the tangent vector concept by introducing two seemingly-different definitions (either of which are common among the relativity literature) and then formally proving their equivalence (done nowhere in the literature). I appreciated the demonstration of equivalence, and will sketch it below.\n\nTangent Vectors Geometrically\nIsham first introduces tangent vectors in the familiar, geometric manner. If we let \\(\\gamma_1(\\lambda)\\) and \\(\\gamma_2(\\lambda)\\) be curves passing through a point \\(p\\) on a patch of the manifold \\(\\mathcal{M}\\) such that \\(\\gamma_1(\\lambda=0) = \\gamma_2(\\lambda=0) = p\\), then it is natural to define the tangent vector \\(v_p\\) at \\(p\\) as an equivalence class of curves, denoted \\([\\gamma]\\), where the equivalence criteria is defined by sharing the tangent vector \\(v_p\\):\n\\[\n\\left. \\frac{d x^{\\mu}}{d \\lambda} (\\gamma_1(\\lambda)) \\right|_{\\lambda=0} = v_p = \\left. \\frac{d x^{\\mu}}{d \\lambda} (\\gamma_2(\\lambda)) \\right|_{\\lambda=0}\n\\]\nThe tangent space \\(T_p \\mathcal{M}\\) can then be defined as the set of all tangent vectors at the point \\(p\\), or the set of all equivalence classes of curves at the point \\(p\\).\n\n\nTangent Vectors Algebraically\nThe algebraic approach begins with the concept of a derivation, or directional derivative, \\(v\\) as a map that is both linear and obeys the Leibniz rule. By thinking of the smooth functions on the manifold \\(C^{\\infty}(\\mathcal{M})\\) as a ring over \\(\\mathbb{R}\\), we can define the map \\(v: C^{\\infty}(\\mathcal{M}) \\to \\mathbb{R}\\) as:\n\\[\nv(f) \\equiv \\left. \\frac{df\\left( \\gamma(\\lambda) \\right)}{d\\lambda} \\right|_{\\lambda=0} \\quad\\text{ where }\\quad [\\gamma] = v\n\\]\nBy linear, we mean that for any \\(f, g \\in C^{\\infty}(\\mathcal{M})\\) and \\(r, s \\in \\mathbb{R}\\), we have \\(v(rf + sg) = rv(f) + sv(g)\\), and by Leibniz rule we mean \\(v(fg) = f(p)v(g) + g(p)v(f)\\). The set of all derivations at a point \\(p\\) is denoted \\(D_p \\mathcal{M}\\).\n\n\nEquivalence of Definitions\nIsham shows that these two definitions of the tangent space, \\(T_p \\mathcal{M}\\) and \\(D_p \\mathcal{M}\\), are equivalent by proving that the natural map between them \\(\\iota\\) is, in fact, an isomorphism, where \\(\\iota: T_p\\mathcal{M} \\to D_p\\mathcal{M}\\) is defined as:\n\\[\n\\iota(v)(f) \\equiv \\left. \\frac{df \\left(\\gamma\\left(\\lambda\\right)\\right) }{d\\lambda} \\right|_{\\lambda=0}\n\\]\nTo show that \\(\\iota\\) is an isomorphism, Isham demonstrates that it is both injective (one-to-one) and surjective (onto). To show injectivity, assume that \\(\\iota([\\gamma_1]) = \\iota([\\gamma_2])\\), then we must have:\n\\[\n\\left. \\frac{df \\left(\\gamma_1\\left(\\lambda\\right)\\right) }{d\\lambda} \\right|_{\\lambda=0}\n\\]\nThe above shows that both \\(\\gamma_1\\) and \\(\\gamma_2\\) are tangent at \\(p\\), which implies that they are, in fact, equivalent. Therefore \\([\\gamma_1] = [\\gamma_2]\\), and \\(\\iota\\) is injective.\nTo show that \\(\\iota\\) is surjective we choose an element \\(v\\) of the range \\(D_p\\mathcal{M}\\) and define a curve \\(\\gamma_v\\) such that \\(\\gamma_v(0)=p\\) and \\(v(x^{\\mu})=\\frac{d}{d\\lambda}x^{\\mu}\\circ\\gamma(\\lambda)|_{\\lambda=0}\\). Recall that we can expand a tangent vector as \\(v_p\\) in terms of derivatives of a coordinate system \\(x^{\\mu}\\) as \\(v = v^{\\mu}\\partial_{\\mu}\\) and therefore \\(v(f) = v^{\\mu} \\partial_{\\mu} f = \\frac{d}{d\\lambda} x^{\\mu} \\circ \\gamma_v |_{\\lambda=0} \\partial_{\\mu} f\\). But Isham shows:\n\\[\n\\begin{align}\n\\left. \\frac{d}{d\\lambda} f\\circ \\gamma_v \\right|_{\\lambda=0} &= \\left. \\frac{d}{d\\lambda}(f \\circ \\phi^{-1} \\circ \\phi \\circ \\gamma_v) \\right|_{\\lambda=0} \\\\\n&= \\sum_{\\mu} \\left. \\frac{\\partial}{\\partial u^{\\mu}} (f\\circ \\phi^{-1}) \\right|_{\\phi(p)} \\left. \\frac{d}{d\\lambda} u^{\\mu} (\\phi \\circ \\gamma_v) \\right|_{\\lambda=0} \\\\\n&= \\sum_{\\mu} \\left(\\frac{\\partial}{\\partial x^{\\mu}}\\right)_{p} f \\left. \\frac{d}{d\\lambda} x^{\\mu} \\circ \\gamma_v(\\lambda) \\right|_{\\lambda=0} = v(f)\n\\end{align}\n\\]\nSince \\(\\frac{d}{d\\lambda} f \\circ \\gamma_v |_{\\lambda=0} = v(f)\\), then \\([\\gamma_v](f) = v(f)\\) and therefore \\(\\iota\\) is surjective. This completes the proof, and we can robustly conclude that the geometric and algebraic pictures are formally equivalent! We are then free to use either where convenient."
  },
  {
    "objectID": "posts/20210919-recent-finds.html#swarms-of-searching-particles",
    "href": "posts/20210919-recent-finds.html#swarms-of-searching-particles",
    "title": "Recent Finds #1",
    "section": "Swarms of Searching Particles",
    "text": "Swarms of Searching Particles\nDuring a recent talk the subject of optimization arose in the context of gravitational wave detection.  [2] Though interested in the application (my present research overlaps heavily with GW detection), the general concept of particle swarm optimization (PSO) captured my attention.\nThis optimization method involves an initial distribution of \\(m\\) particles \\(\\{x^{\\mu}_{k}\\}\\) in the \\(n\\)-dimensional parameter space \\(\\mathcal{M}\\) of some measure of quality \\(f: \\mathcal{M} \\to \\mathbb{R}\\), where \\(\\mu = 1, \\dots, n\\) refers to the coordinate in \\(\\mathcal{M}\\) and \\(k = 1, \\dots, m\\) refers to the particle number. Each particle is initialized with some velocity, and the velocity is updated throughout each iteration of the algorithm. Interestingly, the particles are not computing local gradients, rather, their velocities are updated using a randomized combination of local (nearest-neighbors-in-swarm) and global (all-swarm) information. The iteration rule can be summarized broadly by the equation below.\n\\[\n\\begin{align}\nv^{\\mu}_{k}(t) &= c_0 v^{\\mu}_{k}(t - \\Delta t) \\\\\n&+ c_1 r_1 \\left[\\eta^{\\mu}_k(t - \\Delta t) - x^{\\mu}_k(t - \\Delta t)\\right] \\\\\n&+ c_2 r_2 \\left[\\zeta^{\\mu}(t - \\Delta t) - x^{\\mu}_k(t - \\Delta t)\\right]\n\\end{align}\n\\]\nWhere the variable \\(\\eta^{\\mu}_k\\) represents the best known position of the local neighbors of particle \\(k\\) and the variable \\(\\zeta^{\\mu}\\) represents the best known position of the entire swarm (also called the global best). The term best here refers to the type of optimization, in our example we would maximizing our quality function \\(f\\), so for example \\(\\zeta^{\\mu}\\) is the position in the swarm that corresponds to the larges value of \\(f\\). When the velocity updates, the algorithm is essentially trying to mix three things:\n\nThe previous direction of the particle\nThe direction towards the known, local optimum\nThe direction towards the known, global optimum\n\nThe numbers \\((r_1, r_2)\\) are randomly generated each iteration, and allow the particles to explore more of the parameter space instead of moving directly towards their known, best locations. Lastly, the constants \\((c_0, c_1, c_2)\\) are tuning parameters that control how to weight the particle, local, and global information when updating particle velocities. The image below represents a sample of PSO in a two-dimensional setting.\n\n\n\n\n\n\nFigure 1: Particle Swarm Optimization Example (Ephramac, CC BY-SA via Wikimedia Commons)\n\n\n\nFor further reading, the PSO algorithm has been studied extensively in general.  [3,4] PSO has also been used in a variety of scientific fields, such as gravitational wave analysis,  [5] and has even been used in industry settings, such as financial portfolio optimization."
  },
  {
    "objectID": "posts/20210919-recent-finds.html#references",
    "href": "posts/20210919-recent-finds.html#references",
    "title": "Recent Finds #1",
    "section": "References",
    "text": "References\n\n\n[1] C. J. Isham, Modern Differential Geometry for Physicists, 2nd ed. (World Scientific, Singapore, 1999).\n\n\n[2] S. Adhicary, Advance alerts from gravitational wave searches of binary compact objects for electromagnetic follow-ups, (2021).\n\n\n[3] R. Chen, W. K. Huang, and S. Yeh, Particle swarm optimization approach to portfolio construction, 28, 53 (2021).\n\n\n[4] M. Clerc, Particle Swarm Optimization (ISTE, London, 2006).\n\n\n[5] Y. Wang and S. D. Mohanty, Particle swarm optimization and gravitational wave data analysis: Performance on a binary inspiral testbed, Physical Review D: Particles and Fields 81, 063002 (2010)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a PhD candidate in Physics at The Pennsylvania State University, specializing in General Relativity, Differential Geometry, and High-Performance Computing.\nAs an applied theorist, my research bridges the gap between abstract geometric structures and the rigorous demands of real-time signal analysis. While my primary focus is on gravitational wave astronomy, I am broadly interested in how the tools of mathematical physics, specifically principal bundles and differential forms, can be leveraged to solve practical engineering problems in noise characterization."
  },
  {
    "objectID": "about.html#hi-im-jim.",
    "href": "about.html#hi-im-jim.",
    "title": "About",
    "section": "",
    "text": "I’m a PhD candidate in Physics at The Pennsylvania State University, specializing in General Relativity, Differential Geometry, and High-Performance Computing.\nAs an applied theorist, my research bridges the gap between abstract geometric structures and the rigorous demands of real-time signal analysis. While my primary focus is on gravitational wave astronomy, I am broadly interested in how the tools of mathematical physics, specifically principal bundles and differential forms, can be leveraged to solve practical engineering problems in noise characterization."
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About",
    "section": "Background",
    "text": "Background\nThe through-line of my career has been a fascination with geometry, not just as a mathematical tool, but as the fundamental language of physical law.\nThis interest began during my time at the United States Naval Academy. While the Academy instilled in me a respect for mission-driven engineering, I found myself drawn to the theoretical machinery underneath. Mentorship under Prof. Christopher Morgan, a submarine officer turned astrophysicist, introduced me to the study of Active Galactic Nuclei (AGN) and helped me realize that my contribution to the mission would come from the chalkboard rather than the conning tower.\nI transferred to UT Austin to pursue this depth, pivoting to pure physics and mathematics. There, I immersed myself in the study of dynamical systems and the geometry of phase space, furthering the understanding of dynamics as geometry.\nPrior to my doctoral studies, I spent several years as a quantitative developer at HBK Capital Management. This period was an apprenticeship in software architecture. Designing low-latency, distributed C++/Python systems taught me that elegant theory requires robust implementation. I learned to view code not as a mere script for calculation, but as an architecture that must manage complexity and scale."
  },
  {
    "objectID": "about.html#current-work",
    "href": "about.html#current-work",
    "title": "About",
    "section": "Current Work",
    "text": "Current Work\nAt Penn State, I have returned to theory to apply this industrial rigor to fundamental questions in gravity. My work seeks to bring the precision of differential geometry and the robustness of software engineering to the study of the universe.\nI often find myself venturing into pure mathematical subjects motivated by physical applications, including commutative algebras and information geometry. To foster this interdisciplinary dialogue, I co-founded the Mathematical Aspects of Physics (MAP) seminar, a series designed to connect the Math and Physics departments and explore the deep structures underlying our physical theories.\nFor more details on my research, see the Research page."
  }
]