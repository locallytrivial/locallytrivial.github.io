<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Algebra - Tag - Jim W. Kennington</title><link>http://locallytrivial.com/tags/algebra/</link><description>Algebra - Tag - Jim W. Kennington</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 15 Mar 2020 00:00:00 +0000</lastBuildDate><atom:link href="http://locallytrivial.com/tags/algebra/" rel="self" type="application/rss+xml"/><item><title>Algebra Ladder</title><link>http://locallytrivial.com/posts/algebra-ladder/</link><pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate><author>Jim Kennington</author><guid>http://locallytrivial.com/posts/algebra-ladder/</guid><description><![CDATA[I first encountered a diagram of algebraic structures at the end of Jeevanjee&rsquo;s second chapter, &ldquo;Vector Spaces&rdquo;, which elegantly summarizes the high-level differences in structure between sets, vector spaces, and inner product spaces. 1
This diagram was immensely helpful to me, in that it helped show the relationships between various commonly used objects in mathematical physics. As I&rsquo;ve encountered new structures, I&rsquo;ve attempted to augment this map along two dimensions: a structure dimension that aims to measure the number of attributes an algebraic object has, and a specificity dimension which measures the amount of constraints placed on each attribute.]]></description></item><item><title>Book Review: Tensors and Group Theory for Physicists (Jeevanjee)</title><link>http://locallytrivial.com/posts/book-jeevanjee/</link><pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate><author>Jim Kennington</author><guid>http://locallytrivial.com/posts/book-jeevanjee/</guid><description>Summary I picked up a copy of Nadir Jeevnajee&amp;rsquo;s An Introduction to Tensors and Group Theory for Physicists a few months ago with the intent of skimming through and spending most of my time in reference texts. To my pleasant surprise, I found this text to be self contained - requiring little to no references. The presentation is at once mathematically rigorous and physically intuitive, alluding to well-known examples from physics throughout.</description></item><item><title>Tensor Type Notation</title><link>http://locallytrivial.com/posts/tensor-type-notation/</link><pubDate>Tue, 23 Apr 2019 00:00:00 +0000</pubDate><author>Jim Kennington</author><guid>http://locallytrivial.com/posts/tensor-type-notation/</guid><description>What does type (r, s) mean? I&amp;rsquo;d like to discuss the notation of the tensor type, commonly denoted $(r, s)$ as it relates to the tensor product. Specifically, the ordering of the vector spaces and dual vector spaces involved in the product. The order matters since tensors are typically categorized by the number of vectors and dual vectors they require as arguments. To avoid ambiguity, for a given tensor $T$, I will denote the number of vector arguments as $n_v$ and the number of dual vector arguments as $n_d$.</description></item><item><title>Tensor Product for Programmers</title><link>http://locallytrivial.com/posts/tensor-product-programmer/</link><pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate><author>Jim Kennington</author><guid>http://locallytrivial.com/posts/tensor-product-programmer/</guid><description>The introduction to tensor products and tensor algebras is often riddled with rigor, in which a mathematician would delight but a programmer would despair. I find myself in the intersection of these camps and while I appreciate notation, a simpler introduction is possible using functional programming concepts.
Tensors are defined and introduced in two equivalent ways. The first way, called the &amp;ldquo;expansion coefficient&amp;rdquo; (or array) style of introducing tensors relies on many indices and iterates over the n dimensions of some array (n-dimensional generalization of a matrix).</description></item></channel></rss>